{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: UTF-8\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# =============================================================================\n",
    "# Public estimators\n",
    "# =============================================================================\n",
    "\n",
    "def TrAdaBoost_R2(trans_S, Multi_trans_A, response_S, Multi_response_A, test, N):\n",
    "    \"\"\"Boosting for regression transfer. \n",
    "\n",
    "    Please feel free to open issues in the Github : https://github.com/Bin-Cao/TrAdaboost\n",
    "    or \n",
    "    contact Bin Cao (bcao@shu.edu.cn)\n",
    "    in case of any problems/comments/suggestions in using the code. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trans_S : feature matrix of same-distribution training data\n",
    "\n",
    "    Multi_trans_A : dict, feature matrix of diff-distribution training data\n",
    "    e.g.,\n",
    "    Multi_trans_A = {\n",
    "    'trans_A_1' :  data_1 , \n",
    "    'trans_A_2' : data_2 ,\n",
    "    ......\n",
    "    }\n",
    "\n",
    "    response_S : responses of same-distribution training data, real number\n",
    "\n",
    "    Multi_response_A : dict, responses of diff-distribution training data, real number\n",
    "    e.g.,\n",
    "    Multi_response_A = {\n",
    "    'response_A_1' :  response_1 , \n",
    "    'response_A_2' : response_2 ,\n",
    "    ......\n",
    "    }\n",
    "\n",
    "    test : feature matrix of test data\n",
    "\n",
    "    N: int, the number of estimators in TrAdaBoost_R2\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    # same-distribution training data\n",
    "    tarin_data = pd.read_csv('M_Sdata.csv')\n",
    "    # two diff-distribution training data\n",
    "    A1_tarin_data = pd.read_csv('M_Adata1.csv')\n",
    "    A2_tarin_data = pd.read_csv('M_Adata2.csv')\n",
    "    # test data\n",
    "    test_data = pd.read_csv('M_Tdata.csv')\n",
    "\n",
    "    Multi_trans_A = {\n",
    "    'trans_A_1' : A1_tarin_data.iloc[:,:-1],\n",
    "    'trans_A_2' : A2_tarin_data.iloc[:,:-1]\n",
    "    }\n",
    "    Multi_response_A = {\n",
    "    'response_A_1' :  A1_tarin_data.iloc[:,-1] , \n",
    "    'response_A_2' :  A2_tarin_data.iloc[:,-1] ,\n",
    "    }\n",
    "\n",
    "    trans_S = tarin_data.iloc[:,:-1]\n",
    "    response_S = tarin_data.iloc[:, -1]\n",
    "\n",
    "    test = test_data.iloc[:,:-1]\n",
    "    N = 20\n",
    "\n",
    "    TrAdaBoost_R2(trans_S, Multi_trans_A, response_S, Multi_response_A, test, N)\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] section 4.1\n",
    "    Pardoe, D., & Stone, P. (2010, June). \n",
    "    Boosting for regression transfer. \n",
    "    In Proceedings of the 27th International Conference \n",
    "    on International Conference on Machine Learning (pp. 863-870).\n",
    "    \"\"\"\n",
    "\n",
    "     # prepare trans_A\n",
    "    trans_A = list(Multi_trans_A.values())[0]\n",
    "    if len(Multi_trans_A) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(len(Multi_trans_A)-1):\n",
    "            p = i + 1\n",
    "            trans_A = np.concatenate((trans_A, list(Multi_trans_A.values())[p]), axis=0)\n",
    "    # prepare response_A\n",
    "    response_A = list(Multi_response_A.values())[0]\n",
    "    if len(Multi_response_A) == 1:\n",
    "        pass \n",
    "    else:\n",
    "        for i in range(len(Multi_response_A)-1):\n",
    "            p = i + 1\n",
    "            response_A = np.concatenate((response_A, list(Multi_response_A.values())[p]), axis=0)\n",
    "   \n",
    "    trans_data = np.concatenate((trans_A, trans_S), axis=0)\n",
    "    trans_response = np.concatenate((response_A, response_S), axis=0)\n",
    "\n",
    "    row_A = trans_A.shape[0]\n",
    "    row_S = trans_S.shape[0]\n",
    "    row_T = test.shape[0]\n",
    "\n",
    "    if N > row_A:\n",
    "        print('The maximum of iterations should be smaller than ', row_A)\n",
    "        \n",
    "    test_data = np.concatenate((trans_data, test), axis=0)\n",
    "\n",
    "    # Initialize the weights\n",
    "    weights_A = np.ones([row_A, 1]) / row_A\n",
    "    weights_S = np.ones([row_S, 1]) / row_S\n",
    "    weights = np.concatenate((weights_A, weights_S), axis=0) \n",
    "\n",
    "    bata = 1 / (1 + np.sqrt(2 * np.log(row_A / N)))\n",
    "\n",
    "    # Save prediction response and bata_t\n",
    "    bata_T = np.zeros([1, N])\n",
    "    result_response = np.ones([row_A + row_S + row_T, N])\n",
    "\n",
    "    # Save the prediction response of test data \n",
    "    predict = np.zeros([row_T])\n",
    "    print ('params initial finished.')\n",
    "    print('='*60)\n",
    "\n",
    "    trans_data = np.asarray(trans_data, order='C')\n",
    "    trans_response = np.asarray(trans_response, order='C')\n",
    "    test_data = np.asarray(test_data, order='C')\n",
    "\n",
    "    for i in range(N):\n",
    "        weights = calculate_P(weights)\n",
    "        result_response[:, i] = base_regressor(trans_data, trans_response, test_data, weights)\n",
    "        error_rate = calculate_error_rate(response_S, result_response[row_A:row_A + row_S, i],weights[row_A:row_A + row_S, 0])\n",
    "        # Avoiding overfitting\n",
    "        if error_rate <= 1e-10 or error_rate > 0.5:\n",
    "            N = i\n",
    "            break \n",
    "        bata_T[0, i] = error_rate / (1 - error_rate)\n",
    "        print ('Iter {}-th result :'.format(i))\n",
    "        print ('error rate :', error_rate, '|| bata_T :', error_rate / (1 - error_rate))\n",
    "        print('-'*60)\n",
    "\n",
    "        D_t = np.abs(np.array(result_response[:row_A + row_S, i]) - np.array(trans_response)).max()\n",
    "        # Changing the data weights of same-distribution training data\n",
    "        for j in range(row_S):\n",
    "            weights[row_A + j] = weights[row_A + j] * np.power(bata_T[0, i], -(np.abs(result_response[row_A + j, i] - response_S[j])/D_t))\n",
    "        # Changing the data weights of diff-distribution training data\n",
    "        for j in range(row_A):\n",
    "            weights[j] = weights[j] * np.power(bata, np.abs(result_response[j, i] - response_A[j])/D_t)\n",
    "    for i in range(row_T):\n",
    "        predict[i] = np.sum(\n",
    "            result_response[row_A + row_S + i, int(np.floor(N / 2)):N]) / (N-int(np.floor(N / 2)))\n",
    "        \n",
    "    print(\"TrAdaBoost_R2 is done\")\n",
    "    print('='*60)\n",
    "    print('The prediction responses of test data are :')\n",
    "    print(predict)\n",
    "    return predict\n",
    "\n",
    "def calculate_P(weights):\n",
    "    total = np.sum(weights)\n",
    "    return np.asarray(weights / total, order='C')\n",
    "\n",
    "\n",
    "def base_regressor(trans_data, trans_response, test_data, weights):\n",
    "    \"\"\"\n",
    "    Base on sampling\n",
    "    # weight resampling \n",
    "    cdf = np.cumsum(weights)\n",
    "    cdf_ = cdf / cdf[-1]\n",
    "    uniform_samples = np.random.random_sample(len(trans_data))\n",
    "    bootstrap_idx = cdf_.searchsorted(uniform_samples, side='right')\n",
    "    # searchsorted returns a scalar\n",
    "    bootstrap_idx = np.array(bootstrap_idx, copy=False)\n",
    "    reg = DecisionTreeRegressor(max_depth=2,splitter='random',max_features=\"log2\",random_state=0)\n",
    "    reg.fit(trans_data[bootstrap_idx], trans_response[bootstrap_idx])\n",
    "    \"\"\"\n",
    "    # reg = DecisionTreeRegressor(max_depth=1,splitter='random',max_features=\"log2\",random_state=0)\n",
    "    # reg.fit(trans_data, trans_response,sample_weight=weights[:,0])\n",
    "    # return reg.predict(test_data)\n",
    "    return base_LSTM()\n",
    "\n",
    "import keras\n",
    "def base_LSTM(train, response, weight, N=20):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.LSTM(32, input_shape=(train.shape[1], 1)))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    train = np.reshape(train, (train.shape[0], train.shape[1], 1))\n",
    "    model.fit(train, response, epochs=N, batch_size=1, verbose=2)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def calculate_error_rate(response_R, response_H, weight):\n",
    "    total = np.abs(response_R - response_H).max()\n",
    "    return np.sum(weight[:] * np.abs(response_R - response_H) / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
